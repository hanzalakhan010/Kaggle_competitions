{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,StackingClassifier,GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.drop(columns=[\"Ticket\",'Cabin','PassengerId',\"Name\"],inplace=True)\n",
    "df = pd.get_dummies(df,columns=['Embarked',\"Sex\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['Survived'])\n",
    "y = df['Survived']\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'scoring' parameter of GridSearchCV must be a str among {'top_k_accuracy', 'neg_mean_poisson_deviance', 'precision_micro', 'neg_median_absolute_error', 'recall_macro', 'f1', 'average_precision', 'recall_weighted', 'f1_macro', 'jaccard_samples', 'adjusted_mutual_info_score', 'jaccard_micro', 'f1_weighted', 'explained_variance', 'neg_mean_absolute_error', 'normalized_mutual_info_score', 'neg_mean_absolute_percentage_error', 'recall_samples', 'neg_negative_likelihood_ratio', 'recall_micro', 'precision_macro', 'roc_auc_ovo', 'neg_brier_score', 'homogeneity_score', 'neg_root_mean_squared_log_error', 'neg_mean_gamma_deviance', 'jaccard', 'jaccard_weighted', 'adjusted_rand_score', 'balanced_accuracy', 'precision_samples', 'jaccard_macro', 'roc_auc', 'roc_auc_ovo_weighted', 'precision', 'roc_auc_ovr', 'r2', 'positive_likelihood_ratio', 'matthews_corrcoef', 'neg_root_mean_squared_error', 'neg_mean_squared_log_error', 'f1_samples', 'neg_max_error', 'd2_absolute_error_score', 'fowlkes_mallows_score', 'precision_weighted', 'recall', 'mutual_info_score', 'rand_score', 'neg_log_loss', 'neg_mean_squared_error', 'v_measure_score', 'accuracy', 'completeness_score', 'roc_auc_ovr_weighted', 'f1_micro'}, a callable, an instance of 'list', an instance of 'tuple', an instance of 'dict' or None. Got 'accurarcy' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m/media/hanzalak/Hanzala/Projects/Kaggle_competitions/titanic/model2.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/hanzalak/Hanzala/Projects/Kaggle_competitions/titanic/model2.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m param_grid \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/hanzalak/Hanzala/Projects/Kaggle_competitions/titanic/model2.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mdt__max_depth\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m2\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m6\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/hanzalak/Hanzala/Projects/Kaggle_competitions/titanic/model2.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfinal_estimator__n_estimators\u001b[39m\u001b[39m'\u001b[39m:[\u001b[39m70\u001b[39m,\u001b[39m80\u001b[39m,\u001b[39m90\u001b[39m,\u001b[39m100\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/hanzalak/Hanzala/Projects/Kaggle_competitions/titanic/model2.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/hanzalak/Hanzala/Projects/Kaggle_competitions/titanic/model2.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(model,param_grid\u001b[39m=\u001b[39mparam_grid,scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccurarcy\u001b[39m\u001b[39m'\u001b[39m,cv \u001b[39m=\u001b[39m\u001b[39m5\u001b[39m ,n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/hanzalak/Hanzala/Projects/Kaggle_competitions/titanic/model2.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m grid\u001b[39m.\u001b[39;49mfit(X,y)\n",
      "File \u001b[0;32m/media/hanzalak/Hanzala/Projects/Kaggle_competitions/env/lib/python3.11/site-packages/sklearn/base.py:1382\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1377\u001b[0m partial_fit_and_fitted \u001b[39m=\u001b[39m (\n\u001b[1;32m   1378\u001b[0m     fit_method\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpartial_fit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1379\u001b[0m )\n\u001b[1;32m   1381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m global_skip_validation \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1382\u001b[0m     estimator\u001b[39m.\u001b[39;49m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[1;32m   1389\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/media/hanzalak/Hanzala/Projects/Kaggle_competitions/env/lib/python3.11/site-packages/sklearn/base.py:436\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    429\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \n\u001b[1;32m    431\u001b[0m \u001b[39m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m     validate_parameter_constraints(\n\u001b[1;32m    437\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parameter_constraints,\n\u001b[1;32m    438\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(deep\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    439\u001b[0m         caller_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n\u001b[1;32m    440\u001b[0m     )\n",
      "File \u001b[0;32m/media/hanzalak/Hanzala/Projects/Kaggle_competitions/env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:98\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[1;32m     94\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c)\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39mconstraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m     )\n\u001b[0;32m---> 98\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     99\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'scoring' parameter of GridSearchCV must be a str among {'top_k_accuracy', 'neg_mean_poisson_deviance', 'precision_micro', 'neg_median_absolute_error', 'recall_macro', 'f1', 'average_precision', 'recall_weighted', 'f1_macro', 'jaccard_samples', 'adjusted_mutual_info_score', 'jaccard_micro', 'f1_weighted', 'explained_variance', 'neg_mean_absolute_error', 'normalized_mutual_info_score', 'neg_mean_absolute_percentage_error', 'recall_samples', 'neg_negative_likelihood_ratio', 'recall_micro', 'precision_macro', 'roc_auc_ovo', 'neg_brier_score', 'homogeneity_score', 'neg_root_mean_squared_log_error', 'neg_mean_gamma_deviance', 'jaccard', 'jaccard_weighted', 'adjusted_rand_score', 'balanced_accuracy', 'precision_samples', 'jaccard_macro', 'roc_auc', 'roc_auc_ovo_weighted', 'precision', 'roc_auc_ovr', 'r2', 'positive_likelihood_ratio', 'matthews_corrcoef', 'neg_root_mean_squared_error', 'neg_mean_squared_log_error', 'f1_samples', 'neg_max_error', 'd2_absolute_error_score', 'fowlkes_mallows_score', 'precision_weighted', 'recall', 'mutual_info_score', 'rand_score', 'neg_log_loss', 'neg_mean_squared_error', 'v_measure_score', 'accuracy', 'completeness_score', 'roc_auc_ovr_weighted', 'f1_micro'}, a callable, an instance of 'list', an instance of 'tuple', an instance of 'dict' or None. Got 'accurarcy' instead."
     ]
    }
   ],
   "source": [
    "\n",
    "base_estimators = [\n",
    "    (\"rf\",RandomForestClassifier()),\n",
    "    ('dt',DecisionTreeClassifier(random_state=41))\n",
    "]\n",
    "final_estimator = GradientBoostingClassifier()\n",
    "\n",
    "model = StackingClassifier(\n",
    "    estimators = base_estimators,\n",
    "    final_estimator = final_estimator\n",
    ")\n",
    "param_grid = {\n",
    "    'dt__max_depth':[2,4,6],\n",
    "    'final_estimator__n_estimators':[70,80,90,100]\n",
    "}\n",
    "grid = GridSearchCV(model,param_grid=param_grid,scoring='accuracy',cv =5 ,n_jobs=-1)\n",
    "grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
